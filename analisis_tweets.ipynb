{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "74ad234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import snscrape.modules.twitter as sntwitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4bc1e1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Argentina1985\n",
      "Romina al 9009\n",
      "Peter Lanzani\n",
      "#nadiedicenada\n",
      "Kami\n",
      "MARCOS A LA FINAL\n",
      "Murió\n",
      "Hiroshima\n",
      "Hollywood\n",
      "Darin\n",
      "Regina George\n",
      "Máximo\n",
      "Juli y Romi\n",
      "Dolores Fonzi\n",
      "Antonio Banderas\n",
      "Ibarra\n",
      "Viloni\n",
      "Tolosa Paz\n",
      "Pol Fernández\n",
      "Top Gun\n"
     ]
    }
   ],
   "source": [
    "for trend in scraper.get_items():\n",
    "    print (trend.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1b2c97f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se recopilaron 1000 tweets para el trending topic \"Romina al 9009\"\n",
      "Se recopilaron 2000 tweets para el trending topic \"#Argentina1985\"\n",
      "Se recopilaron 3000 tweets para el trending topic \"#nadiedicenada\"\n",
      "Se recopilaron 4000 tweets para el trending topic \"Peter Lanzani\"\n",
      "Se recopilaron 5000 tweets para el trending topic \"Murió\"\n",
      "Se recopilaron 6000 tweets para el trending topic \"Kami\"\n",
      "Se recopilaron 7000 tweets para el trending topic \"Salma\"\n",
      "Se recopilaron 8000 tweets para el trending topic \"Máximo\"\n",
      "Se recopilaron 9000 tweets para el trending topic \"MARCOS A LA FINAL\"\n",
      "Se recopilaron 10000 tweets para el trending topic \"Hollywood\"\n",
      "Se recopilaron 11000 tweets para el trending topic \"Hiroshima\"\n",
      "Se recopilaron 12000 tweets para el trending topic \"Darin\"\n",
      "Se recopilaron 13000 tweets para el trending topic \"Zambia\"\n",
      "Se recopilaron 14000 tweets para el trending topic \"Cristina\"\n",
      "Se recopilaron 15000 tweets para el trending topic \"Barco\"\n",
      "Se recopilaron 16000 tweets para el trending topic \"Juli y Romi\"\n",
      "Se recopilaron 17000 tweets para el trending topic \"CNCO\"\n",
      "Se recopilaron 18000 tweets para el trending topic \"Banfield\"\n",
      "Se recopilaron 19000 tweets para el trending topic \"Dolores Fonzi\"\n",
      "Se recopilaron 20000 tweets para el trending topic \"Viloni\"\n"
     ]
    }
   ],
   "source": [
    "#scraper\n",
    "\n",
    "#for trend in scraper.get_items():\n",
    "#    print(trend.name)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "# Definir la cantidad de tweets a recopilar por cada trending topic\n",
    "num_tweets = 50000 // 50 # Redondeo entero para evitar errores de división\n",
    "\n",
    "# Crear un loop para recopilar los tweets de los trending topics actuales\n",
    "tweets = []\n",
    "for i, trend in enumerate(scraper.get_items()):\n",
    "    if i >= 50: # Detener loop después de 50 trending topics (se pueden modificar)\n",
    "        break\n",
    "    trend_query = trend.name\n",
    "    for j, tweet in enumerate(sntwitter.TwitterSearchScraper(trend_query).get_items()):\n",
    "        if j >= num_tweets:\n",
    "            break\n",
    "        tweets.append(tweet)\n",
    "    print(f'Se recopilaron {len(tweets)} tweets para el trending topic \"{trend_query}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b2ba28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7df552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1f9169cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'snscrape.base' has no attribute 'TwitterTrendScraper'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_83306/1686120074.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Crear un loop para recopilar los tweets de los trending topics actuales\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrend\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msntwitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTwitterTrendScraper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Detener loop después de 50 trending topics (se pueden modificar)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/snscrape/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     24\u001b[0m                         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{name} is deprecated, use {names[name].__name__} instead'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeprecatedFeatureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'module {__name__!r} has no attribute {name!r}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'snscrape.base' has no attribute 'TwitterTrendScraper'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Definir la cantidad de tweets a recopilar por cada trending topic\n",
    "num_tweets = 50000 // 50 # Redondeo entero para evitar errores de división\n",
    "\n",
    "# Crear un loop para recopilar los tweets de los trending topics actuales\n",
    "tweets = []\n",
    "for i, trend in enumerate(sntwitter.TwitterTrendScraper().get_items()):\n",
    "    if i >= 50: # Detener loop después de 50 trending topics (se pueden modificar)\n",
    "        break\n",
    "    trend_query = trend.name\n",
    "    for j, tweet in enumerate(sntwitter.TwitterSearchScraper(trend_query + ' lang:es').get_items()):\n",
    "        if j >= num_tweets:\n",
    "            break\n",
    "        tweets.append(tweet)\n",
    "    print(f'Se recopilaron {len(tweets)} tweets para el trending topic \"{trend_query}\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fa8b80f3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Trend' object has no attribute 'query'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_83306/3757901138.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrend_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msntwitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTwitterSearchScraper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrend_query\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' lang:es'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Trend' object has no attribute 'query'"
     ]
    }
   ],
   "source": [
    "scraper = sntwitter.TwitterTrendsScraper()\n",
    "\n",
    "for i, trend in enumerate(scraper.get_items()):\n",
    "    if i >= 50:\n",
    "        break\n",
    "    trend_query = trend.query\n",
    "    for j, tweet in enumerate(sntwitter.TwitterSearchScraper(trend_query + ' lang:es').get_items()):\n",
    "        \n",
    "        if j >= num_tweets:\n",
    "            break\n",
    "        tweets.append(tweet)\n",
    "        \n",
    "        print(f'Se recopilaron {len(tweets)} tweets para el trending topic \"{trend_query}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "256eebfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snscrape.modules.twitter.TwitterTrendsScraper at 0x7f6126e82c80>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d20f31d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'snscrape.base' has no attribute 'TwitterTrendPager'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_83306/1806137638.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Crear un loop para recopilar los tweets de los trending topics actuales\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrend\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msntwitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTwitterTrendPager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Detener loop después de 50 trending topics (se pueden modificar)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/snscrape/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     24\u001b[0m                         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{name} is deprecated, use {names[name].__name__} instead'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeprecatedFeatureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'module {__name__!r} has no attribute {name!r}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'snscrape.base' has no attribute 'TwitterTrendPager'"
     ]
    }
   ],
   "source": [
    "# Definir la cantidad de tweets a recopilar por cada trending topic\n",
    "num_tweets = 50000 // 50 # Redondeo entero para evitar errores de división\n",
    "\n",
    "# Crear un loop para recopilar los tweets de los trending topics actuales\n",
    "tweets = []\n",
    "for i, trend in enumerate(sntwitter.TwitterTrendPager()):\n",
    "    if i >= 50: # Detener loop después de 50 trending topics (se pueden modificar)\n",
    "        break\n",
    "    trend_query = trend.query\n",
    "    for j, tweet in enumerate(sntwitter.TwitterSearchScraper(trend_query + ' lang:es').get_items()):\n",
    "        if j >= num_tweets:\n",
    "            break\n",
    "        tweets.append(tweet)\n",
    "    print(f'Se recopilaron {len(tweets)} tweets para el trending topic \"{trend_query}\"')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aeda42fc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'snscrape.base' has no attribute 'TwitterTrendScraper'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_83306/2439678352.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Obtiene los trending topics actuales de Twitter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msntwitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTwitterTrendScraper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Itera sobre los trending topics y extrae los tweets de cada uno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/snscrape/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     24\u001b[0m                         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{name} is deprecated, use {names[name].__name__} instead'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDeprecatedFeatureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'module {__name__!r} has no attribute {name!r}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'snscrape.base' has no attribute 'TwitterTrendScraper'"
     ]
    }
   ],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "\n",
    "# Define la cantidad de tweets que quieres extraer\n",
    "max_tweets = 500\n",
    "\n",
    "# Obtiene los trending topics actuales de Twitter\n",
    "trends = sntwitter.TwitterTrendScraper()\n",
    "\n",
    "# Itera sobre los trending topics y extrae los tweets de cada uno\n",
    "tweets_list = []\n",
    "for trend in trends.get_trends():\n",
    "    trend_query = '{} lang:es'.format(trend.query)\n",
    "    tweets = sntwitter.TwitterSearchScraper(trend_query).get_items()\n",
    "    for tweet in tweets:\n",
    "        if len(tweets_list) < max_tweets:\n",
    "            tweets_list.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "        else:\n",
    "            break\n",
    "    else:\n",
    "        continue\n",
    "    break\n",
    "\n",
    "# Convierte la lista de tweets en un DataFrame de pandas\n",
    "tweets_df = pd.DataFrame(tweets_list, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])\n",
    "\n",
    "# Muestra los primeros 5 tweets\n",
    "print(tweets_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23d1adc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'TwitterTrendsScraper' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_83306/2451517546.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Crear un loop para recopilar los tweets de los trending topics actuales\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrend\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msntwitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTwitterTrendsScraper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Detener loop después de 50 trending topics (se pueden modificar)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'TwitterTrendsScraper' object is not iterable"
     ]
    }
   ],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "\n",
    "# Definir la cantidad de tweets a recopilar por cada trending topic\n",
    "num_tweets = 50000 // 50 # Redondeo entero para evitar errores de división\n",
    "\n",
    "# Crear un loop para recopilar los tweets de los trending topics actuales\n",
    "tweets = []\n",
    "for i, trend in enumerate(sntwitter.TwitterTrendsScraper()):\n",
    "    if i >= 50: # Detener loop después de 50 trending topics (se pueden modificar)\n",
    "        break\n",
    "    trend_query = trend.query\n",
    "    for j, tweet in enumerate(sntwitter.TwitterSearchScraper(trend_query + ' lang:es').get_items()):\n",
    "        if j >= num_tweets:\n",
    "            break\n",
    "        tweets.append(tweet)\n",
    "    print(f'Se recopilaron {len(tweets)} tweets para el trending topic \"{trend_query}\"')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
